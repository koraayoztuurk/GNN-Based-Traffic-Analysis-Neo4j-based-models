#!/usr/bin/env python3
"""
08_auto_pipeline.py
-------------------
HERE Traffic â†’ Neo4j tam otomatik pipeline

Bu script ÅŸu adÄ±mlarÄ± otomatik yapar:
1. HERE API'den trafik verisi Ã§eker (01_fetch_here_flow.py)
2. Harita render eder ve GeoJSON arÅŸivler (02_render_flow_map.py)
3. ArÅŸivlerden timeseries oluÅŸturur (05_build_timeseries.py)
4. Neo4j'ye yÃ¼kler (07_silent_load_to_neo4j.py)

KullanÄ±m:
  # Tek seferlik Ã§alÄ±ÅŸtÄ±r:
  python 08_auto_pipeline.py

  # Belirli aralÄ±klarla sÃ¼rekli Ã§alÄ±ÅŸtÄ±r (15 dk):
  python 08_auto_pipeline.py --loop --interval 15

  # Sadece mevcut arÅŸivleri yÃ¼kle (HERE Ã§ekme YOK):
  python 08_auto_pipeline.py --skip-fetch

  # DetaylÄ± log:
  python 08_auto_pipeline.py --verbose
"""
import os
import sys
import subprocess
import argparse
import time
import logging
from pathlib import Path
from datetime import datetime

# ---------- .env Loader ----------
ROOT_DIR = Path(__file__).parent.parent.parent

def load_env():
    """Load .env file into environment variables"""
    env_file = ROOT_DIR / "config" / ".env"
    if env_file.exists():
        for line in env_file.read_text(encoding="utf-8").splitlines():
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            if "#" in line:
                line = line.split("#", 1)[0].strip()
            if "=" not in line:
                continue
            key, value = line.split("=", 1)
            os.environ.setdefault(key.strip(), value.strip())

def get_env_int(key, default):
    """Get integer value from environment"""
    val = os.environ.get(key)
    if val is None:
        return default
    try:
        return int(val)
    except ValueError:
        # Extract digits only (e.g., "15 min" -> 15)
        digits = "".join(ch for ch in val if ch.isdigit())
        return int(digits) if digits else default

# Load .env at module level
load_env()

# ---------- Logging AyarlarÄ± ----------
def setup_logging(verbose=False):
    """Hem konsol hem dosya logging"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    log_file = log_dir / f"pipeline_{datetime.now().strftime('%Y%m%d')}.log"
    
    level = logging.DEBUG if verbose else logging.INFO
    
    # Format
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Dosya handler
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(formatter)
    file_handler.setLevel(logging.DEBUG)
    
    # Konsol handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    console_handler.setLevel(level)
    
    # Root logger
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

# ---------- Script Ã‡alÄ±ÅŸtÄ±rÄ±cÄ± ----------
def run_script(script_name, args=None, timeout=300, critical=True):
    """
    Python script Ã§alÄ±ÅŸtÄ±r ve sonucu dÃ¶ndÃ¼r
    
    Args:
        script_name: Ã‡alÄ±ÅŸtÄ±rÄ±lacak script (Ã¶rn: "01_fetch_here_flow.py")
        args: Opsiyonel argÃ¼manlar (list)
        timeout: Maksimum bekleme sÃ¼resi (saniye)
        critical: Hata durumunda pipeline'Ä± durdur mu?
    
    Returns:
        (success: bool, output: str)
    """
    logger = logging.getLogger()
    
    # Script path'ini ROOT_DIR'e gÃ¶re oluÅŸtur
    if script_name.startswith("07_"):
        script_path = ROOT_DIR / "src" / "neo4j" / script_name
    elif script_name == "ensure_topology.py":
        script_path = ROOT_DIR / "src" / "gnn" / script_name
    else:
        script_path = ROOT_DIR / "src" / "pipeline" / script_name
    
    cmd = [sys.executable, str(script_path)]
    if args:
        cmd.extend(args)
    
    logger.info(f"â–¶ï¸  Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±yor: {' '.join(cmd)}")
    
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout,
            encoding='utf-8',
            errors='replace'
        )
        
        # Ã‡Ä±ktÄ±larÄ± logla
        if result.stdout:
            for line in result.stdout.strip().split('\n'):
                logger.debug(f"   {line}")
        
        if result.returncode == 0:
            logger.info(f"âœ… {script_name} baÅŸarÄ±lÄ± (exit code: 0)")
            return True, result.stdout
        else:
            logger.error(f"âŒ {script_name} hata verdi (exit code: {result.returncode})")
            if result.stderr:
                logger.error(f"STDERR:\n{result.stderr}")
            
            if critical:
                logger.critical(f"Pipeline durduruluyor: {script_name} kritik hata!")
                sys.exit(1)
            
            return False, result.stderr
    
    except subprocess.TimeoutExpired:
        logger.error(f"â±ï¸  {script_name} timeout! ({timeout}s)")
        if critical:
            sys.exit(1)
        return False, "TIMEOUT"
    
    except Exception as e:
        logger.error(f"ğŸ’¥ {script_name} beklenmedik hata: {e}")
        if critical:
            sys.exit(1)
        return False, str(e)

# ---------- Pipeline AdÄ±mlarÄ± ----------
def step_fetch_here_flow():
    """1. HERE API'den veri Ã§ek"""
    logger = logging.getLogger()
    logger.info("=" * 70)
    logger.info("ADIM 1: HERE Traffic Flow veri Ã§ekme")
    logger.info("=" * 70)
    
    return run_script("01_fetch_here_flow.py", timeout=60, critical=True)

def step_render_map():
    """2. Harita render et ve arÅŸivle"""
    logger = logging.getLogger()
    logger.info("=" * 70)
    logger.info("ADIM 2: Harita render ve GeoJSON arÅŸivleme")
    logger.info("=" * 70)
    
    return run_script("02_render_flow_map.py", timeout=60, critical=True)

def step_build_timeseries():
    """3. ArÅŸivlerden timeseries.parquet oluÅŸtur"""
    logger = logging.getLogger()
    logger.info("=" * 70)
    logger.info("ADIM 3: Timeseries (Parquet) oluÅŸturma")
    logger.info("=" * 70)
    
    # ArÅŸivde dosya var mÄ± kontrol et
    archive_dir = Path("archive")
    if not archive_dir.exists():
        logger.warning("âš ï¸  archive/ klasÃ¶rÃ¼ yok, oluÅŸturuluyor...")
        archive_dir.mkdir(parents=True, exist_ok=True)
    
    geojson_files = list(archive_dir.glob("flow_*.geojson"))
    if not geojson_files:
        logger.warning("âš ï¸  archive/ iÃ§inde GeoJSON dosyasÄ± yok!")
        logger.warning("   Ä°lk fetch yaptÄ±ysan bu normal, bir sonraki Ã§alÄ±ÅŸmada yÃ¼klenecek.")
        return False, "NO_ARCHIVE_FILES"
    
    logger.info(f"ğŸ“ {len(geojson_files)} adet arÅŸiv dosyasÄ± bulundu")
    
    return run_script("05_build_timeseries.py", timeout=300, critical=False)

def step_ensure_topology():
    """3.5. Topoloji kontrolÃ¼ ve oluÅŸturma (akÄ±llÄ±)"""
    logger = logging.getLogger()
    logger.info("=" * 70)
    logger.info("ADIM 3.5: Topoloji KontrolÃ¼ (CONNECTS_TO)")
    logger.info("=" * 70)
    
    return run_script("ensure_topology.py", timeout=900, critical=False)

def step_load_neo4j():
    """4. Neo4j'ye yÃ¼kle"""
    logger = logging.getLogger()
    logger.info("=" * 70)
    logger.info("ADIM 4: Neo4j'ye veri yÃ¼kleme")
    logger.info("=" * 70)
    
    # Gerekli dosyalarÄ± kontrol et
    required = [
        Path("data/edges_static.geojson"),
        Path("data/timeseries.parquet")
    ]
    
    missing = [f for f in required if not f.exists()]
    if missing:
        logger.error(f"âŒ Eksik dosya(lar): {[str(f) for f in missing]}")
        logger.error("   Ã–nce timeseries oluÅŸtur!")
        return False, "MISSING_FILES"
    
    return run_script("07_silent_load_to_neo4j.py", timeout=600, critical=False)

# ---------- Ana Pipeline ----------
def run_full_pipeline(skip_fetch=False):
    """TÃ¼m pipeline'Ä± Ã§alÄ±ÅŸtÄ±r"""
    logger = logging.getLogger()
    
    start_time = datetime.now()
    logger.info("ğŸš€ " * 20)
    logger.info("ğŸš€ OTOMATIK PIPELINE BAÅLIYOR")
    logger.info(f"ğŸš€ BaÅŸlangÄ±Ã§: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("ğŸš€ " * 20)
    
    results = {}
    
    # 1. HERE veri Ã§ekme (opsiyonel)
    if skip_fetch:
        logger.info("â­ï¸  ADIM 1 atlanÄ±yor (--skip-fetch)")
        results['fetch'] = (True, "SKIPPED")
    else:
        results['fetch'] = step_fetch_here_flow()
    
    # 2. Harita render (sadece fetch yapÄ±ldÄ±ysa)
    if not skip_fetch:
        results['render'] = step_render_map()
    else:
        logger.info("â­ï¸  ADIM 2 atlanÄ±yor (fetch yapÄ±lmadÄ±)")
        results['render'] = (True, "SKIPPED")
    
    # 3. Timeseries oluÅŸtur
    results['timeseries'] = step_build_timeseries()
    
    # 3.5. Topoloji kontrolÃ¼ (akÄ±llÄ± - yoksa oluÅŸtur)
    results['topology'] = step_ensure_topology()
    
    # 4. Neo4j'ye yÃ¼kle
    results['neo4j'] = step_load_neo4j()
    
    # Ã–zet
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    logger.info("=" * 70)
    logger.info("ğŸ“Š PIPELINE SONUÃ‡LARI")
    logger.info("=" * 70)
    logger.info(f"â±ï¸  Toplam sÃ¼re: {duration:.1f} saniye")
    logger.info("")
    logger.info("AdÄ±m sonuÃ§larÄ±:")
    
    all_success = True
    for step_name, (success, _) in results.items():
        status = "âœ… BAÅARILI" if success else "âŒ HATA"
        logger.info(f"  {step_name:12} â†’ {status}")
        if not success:
            all_success = False
    
    logger.info("=" * 70)
    
    if all_success:
        logger.info("ğŸ‰ TÃœM ADIMLAR BAÅARIYLA TAMAMLANDI!")
    else:
        logger.warning("âš ï¸  BazÄ± adÄ±mlarda hata oluÅŸtu (yukarÄ±daki loglarÄ± incele)")
    
    logger.info("=" * 70)
    
    return all_success

# ---------- Loop Modu ----------
def run_loop_mode(interval_minutes):
    """Belirli aralÄ±klarla pipeline'Ä± sÃ¼rekli Ã§alÄ±ÅŸtÄ±r"""
    logger = logging.getLogger()
    
    logger.info("ğŸ”„ " * 20)
    logger.info(f"ğŸ”„ LOOP MODU AKTIF: Her {interval_minutes} dakikada bir Ã§alÄ±ÅŸacak")
    logger.info("ğŸ”„ Durdurmak iÃ§in: Ctrl + C")
    logger.info("ğŸ”„ " * 20)
    
    iteration = 0
    
    try:
        while True:
            iteration += 1
            logger.info(f"\n{'#' * 70}")
            logger.info(f"# Ä°TERASYON {iteration}")
            logger.info(f"{'#' * 70}\n")
            
            run_full_pipeline(skip_fetch=False)
            
            logger.info(f"\nâ¸ï¸  {interval_minutes} dakika bekleniyor...")
            logger.info(f"   Sonraki Ã§alÄ±ÅŸma: {datetime.now().strftime('%H:%M:%S')} + {interval_minutes} dk\n")
            
            time.sleep(interval_minutes * 60)
    
    except KeyboardInterrupt:
        logger.info("\n\nğŸ›‘ Pipeline kullanÄ±cÄ± tarafÄ±ndan durduruldu (Ctrl+C)")
        logger.info(f"ğŸ“Š Toplam {iteration} iterasyon tamamlandÄ±")
        sys.exit(0)

# ---------- CLI ----------
def main():
    parser = argparse.ArgumentParser(
        description="HERE Traffic â†’ Neo4j tam otomatik pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ã–rnekler:
  # Tek seferlik Ã§alÄ±ÅŸtÄ±r:
  python 08_auto_pipeline.py

  # Her 15 dakikada bir sÃ¼rekli Ã§alÄ±ÅŸtÄ±r:
  python 08_auto_pipeline.py --loop --interval 15

  # Sadece mevcut arÅŸivleri yÃ¼kle (HERE Ã§ekme):
  python 08_auto_pipeline.py --skip-fetch

  # DetaylÄ± log:
  python 08_auto_pipeline.py --verbose
        """
    )
    
    parser.add_argument(
        '--loop',
        action='store_true',
        help='SÃ¼rekli Ã§alÄ±ÅŸma modu (belirtilen aralÄ±klarla tekrar eder)'
    )
    
    parser.add_argument(
        '--interval',
        type=int,
        default=None,
        help='Loop modunda bekleme sÃ¼resi (dakika). Belirtilmezse .env dosyasÄ±ndaki PIPELINE_INTERVAL_MIN kullanÄ±lÄ±r'
    )
    
    parser.add_argument(
        '--skip-fetch',
        action='store_true',
        help='HERE veri Ã§ekmeyi atla (sadece mevcut arÅŸivleri yÃ¼kle)'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='DetaylÄ± log Ã§Ä±ktÄ±sÄ± (DEBUG seviye)'
    )
    
    args = parser.parse_args()
    
    # Logging setup
    setup_logging(verbose=args.verbose)
    logger = logging.getLogger()
    
    # Interval'i .env'den veya argÃ¼mandan al
    if args.interval is not None:
        interval = args.interval
    else:
        interval = get_env_int("PIPELINE_INTERVAL_MIN", 15)
    
    logger.info(f"ğŸ“ Pipeline interval: {interval} dakika (.env: PIPELINE_INTERVAL_MIN)")
    
    # Pipeline Ã§alÄ±ÅŸtÄ±r
    if args.loop:
        run_loop_mode(interval)
    else:
        success = run_full_pipeline(skip_fetch=args.skip_fetch)
        sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
